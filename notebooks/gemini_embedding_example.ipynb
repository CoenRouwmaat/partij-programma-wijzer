{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Tce3stUlHN0L"
      },
      "source": [
        "##### Copyright 2025 Google LLC."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "tuOe1ymfHZPu"
      },
      "outputs": [],
      "source": [
        "# @title Licensed under the Apache License, Version 2.0 (the \"License\");\n",
        "# you may not use this file except in compliance with the License.\n",
        "# You may obtain a copy of the License at\n",
        "#\n",
        "# https://www.apache.org/licenses/LICENSE-2.0\n",
        "#\n",
        "# Unless required by applicable law or agreed to in writing, software\n",
        "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
        "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
        "# See the License for the specific language governing permissions and\n",
        "# limitations under the License."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LmfLXp5_bt-a"
      },
      "source": [
        "# Document search with embeddings"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bbPzgYbrwbK2"
      },
      "source": [
        "## Overview\n",
        "\n",
        "This example demonstrates how to use the Gemini API to create embeddings so that you can perform document search. You will use the Python client library to build a word embedding that allows you to compare search strings, or questions, to document contents.\n",
        "\n",
        "In this tutorial, you'll use embeddings to perform document search over a set of documents to ask questions related to the Google Car.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IS2GUSP0_Eim"
      },
      "source": [
        "## Setup"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JIm3gEGYhTX1"
      },
      "outputs": [],
      "source": [
        "from dotenv import load_dotenv\n",
        "from google import genai\n",
        "\n",
        "load_dotenv()\n",
        "\n",
        "client = genai.Client()  # Automatically fetches GEMINI_API_KEY value from .env"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gGpQ8Eg0kNXW"
      },
      "source": [
        "## Embedding generation\n",
        "\n",
        "In this section, you will see how to generate embeddings for a piece of text using the embeddings from the Gemini API.\n",
        "\n",
        "See the [Embeddings quickstart](https://github.com/google-gemini/cookbook/blob/main/quickstarts/Embeddings.ipynb) to learn more about the `task_type` parameter used below."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "J76TNa3QDwCc"
      },
      "outputs": [],
      "source": [
        "from google.genai import types\n",
        "\n",
        "title = \"The next generation of AI for developers and Google Workspace\"\n",
        "sample_text = \"\"\"\n",
        "    Title: The next generation of AI for developers and Google Workspace\n",
        "    Full article:\n",
        "    Gemini API & Google AI Studio: An approachable way to explore and\n",
        "    prototype with generative AI applications\n",
        "\"\"\"\n",
        "\n",
        "EMBEDDING_MODEL_ID = MODEL_ID = \"gemini-embedding-001\"  # @param [\"gemini-embedding-001\", \"text-embedding-004\"] {\"allow-input\": true, \"isTemplate\": true}\n",
        "embedding = client.models.embed_content(\n",
        "        model=EMBEDDING_MODEL_ID,\n",
        "        contents=sample_text,\n",
        "        config=types.EmbedContentConfig(\n",
        "            task_type=\"retrieval_document\",\n",
        "            title=title\n",
        "    ))\n",
        "\n",
        "print(embedding)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dD1lQx3Zr3S2"
      },
      "source": [
        "## Building an embeddings database\n",
        "\n",
        "Here are three sample texts to use to build the embeddings database. You will use the Gemini API to create embeddings of each of the documents. Turn them into a dataframe for better visualization."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XvLRIbpq4vNN"
      },
      "outputs": [],
      "source": [
        "DOCUMENT1 = {\n",
        "    \"title\": \"Operating the Climate Control System\",\n",
        "    \"content\": \"Your Googlecar has a climate control system that allows you to adjust the temperature and airflow in the car. To operate the climate control system, use the buttons and knobs located on the center console.  Temperature: The temperature knob controls the temperature inside the car. Turn the knob clockwise to increase the temperature or counterclockwise to decrease the temperature. Airflow: The airflow knob controls the amount of airflow inside the car. Turn the knob clockwise to increase the airflow or counterclockwise to decrease the airflow. Fan speed: The fan speed knob controls the speed of the fan. Turn the knob clockwise to increase the fan speed or counterclockwise to decrease the fan speed. Mode: The mode button allows you to select the desired mode. The available modes are: Auto: The car will automatically adjust the temperature and airflow to maintain a comfortable level. Cool: The car will blow cool air into the car. Heat: The car will blow warm air into the car. Defrost: The car will blow warm air onto the windshield to defrost it.\"}\n",
        "DOCUMENT2 = {\n",
        "    \"title\": \"Touchscreen\",\n",
        "    \"content\": \"Your Googlecar has a large touchscreen display that provides access to a variety of features, including navigation, entertainment, and climate control. To use the touchscreen display, simply touch the desired icon.  For example, you can touch the \\\"Navigation\\\" icon to get directions to your destination or touch the \\\"Music\\\" icon to play your favorite songs.\"}\n",
        "DOCUMENT3 = {\n",
        "    \"title\": \"Shifting Gears\",\n",
        "    \"content\": \"Your Googlecar has an automatic transmission. To shift gears, simply move the shift lever to the desired position.  Park: This position is used when you are parked. The wheels are locked and the car cannot move. Reverse: This position is used to back up. Neutral: This position is used when you are stopped at a light or in traffic. The car is not in gear and will not move unless you press the gas pedal. Drive: This position is used to drive forward. Low: This position is used for driving in snow or other slippery conditions.\"}\n",
        "\n",
        "documents = [DOCUMENT1, DOCUMENT2, DOCUMENT3]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WwhCQwPbvwc-"
      },
      "source": [
        "Organize the contents of the dictionary into a dataframe for better visualization."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GJKLIW9Z31Vf"
      },
      "outputs": [],
      "source": [
        "import pandas as pd  # This is a package for managing tabular data (excel format)\n",
        "\n",
        "df = pd.DataFrame(documents)\n",
        "df.columns = ['Title', 'Text']\n",
        "df"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LHonPYEwStLB"
      },
      "source": [
        "Get the embeddings for each of these bodies of text. Add this information to the dataframe."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4SOhy0lNBhfN"
      },
      "outputs": [],
      "source": [
        "# Get the embeddings of each text and add to an embeddings column in the dataframe\n",
        "def embed_fn(title, text):\n",
        "  response = client.models.embed_content(\n",
        "        model=EMBEDDING_MODEL_ID,\n",
        "        contents=text,\n",
        "        config=types.EmbedContentConfig(\n",
        "            task_type=\"retrieval_document\",\n",
        "            title=title\n",
        "        )\n",
        "    )\n",
        "\n",
        "  return response.embeddings[0].values\n",
        "\n",
        "df['Embeddings'] = df.apply(lambda row: embed_fn(row['Title'], row['Text']), axis=1)\n",
        "df"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cfm8a31FKd00"
      },
      "source": [
        "## Document search with Q&A\n",
        "\n",
        "Now that the embeddings are generated, let's create a Q&A system to search these documents. You will ask a question about hyperparameter tuning, create an embedding of the question, and compare it against the collection of embeddings in the dataframe.\n",
        "\n",
        "The embedding of the question will be a vector (list of float values), which will be compared against the vector of the documents using the dot product. This vector returned from the API is already normalized. The dot product represents the similarity in direction between two vectors.\n",
        "\n",
        "The values of the dot product can range between -1 and 1, inclusive. If the dot product between two vectors is 1, then the vectors are in the same direction. If the dot product value is 0, then these vectors are orthogonal, or unrelated, to each other. Lastly, if the dot product is -1, then the vectors point in the opposite direction and are not similar to each other.\n",
        "\n",
        "Note, with the new embeddings model (`gemini-embedding-001`), specify the task type as `QUERY` for user query and `DOCUMENT` when embedding a document text.\n",
        "\n",
        "Task Type | Description\n",
        "---       | ---\n",
        "RETRIEVAL_QUERY\t| Specifies the given text is a query in a search/retrieval setting.\n",
        "RETRIEVAL_DOCUMENT | Specifies the given text is a document in a search/retrieval setting."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "80w2VQQ9JWcU"
      },
      "outputs": [],
      "source": [
        "query = \"How to shift gears in the Google car?\"\n",
        "\n",
        "request = client.models.embed_content(\n",
        "    model=EMBEDDING_MODEL_ID,\n",
        "    contents=query,\n",
        "    config=types.EmbedContentConfig(\n",
        "        task_type=\"RETRIEVAL_DOCUMENT\",\n",
        "        )\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iivgDQej5Agt"
      },
      "source": [
        "Use the `find_best_passage` function to calculate the dot products, and then sort the dataframe from the largest to smallest dot product value to retrieve the relevant passage out of the database."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "am36P3J9M6Zv"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "\n",
        "def find_best_passage(query, dataframe):\n",
        "  \"\"\"\n",
        "  Compute the distances between the query and each document in the dataframe\n",
        "  using the dot product.\n",
        "  \"\"\"\n",
        "  query_embedding = client.models.embed_content(\n",
        "      model=EMBEDDING_MODEL_ID,\n",
        "      contents=query,\n",
        "      config=types.EmbedContentConfig(\n",
        "          task_type=\"retrieval_document\",\n",
        "          )\n",
        "  )\n",
        "\n",
        "  dot_products = np.dot(\n",
        "      np.stack(dataframe['Embeddings']),\n",
        "      query_embedding.embeddings[0].values\n",
        "  )\n",
        "  idx = np.argmax(dot_products)\n",
        "  return dataframe.iloc[idx]['Text'] # Return text from index with max value"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Uq-bpLZm9DKo"
      },
      "source": [
        "View the most relevant document from the database:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1I5lAqdH9zWL"
      },
      "outputs": [],
      "source": [
        "from IPython.display import Markdown\n",
        "\n",
        "passage = find_best_passage(query, df)\n",
        "Markdown(passage)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ebkGT0ha5Ln3"
      },
      "source": [
        "## Question and Answering Application\n",
        "\n",
        "Let's try to use the text generation API to create a Q & A system. Input your own custom data below to create a simple question and answering example. You will still use the dot product as a metric of similarity."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pqf-OsT3auTm"
      },
      "outputs": [],
      "source": [
        "import textwrap\n",
        "\n",
        "def make_prompt(query, relevant_passage):\n",
        "  escaped = (\n",
        "      relevant_passage\n",
        "      .replace(\"'\", \"\")\n",
        "      .replace('\"', \"\")\n",
        "      .replace(\"\\n\", \" \")\n",
        "  )\n",
        "  prompt = textwrap.dedent(\"\"\"\n",
        "    You are a helpful and informative bot that answers questions using text\n",
        "    from the reference passage included below. Be sure to respond in a\n",
        "    complete sentence, being comprehensive, including all relevant\n",
        "    background information.\n",
        "\n",
        "    However, you are talking to a non-technical audience, so be sure to\n",
        "    break down complicated concepts and strike a friendly and conversational\n",
        "    tone. If the passage is irrelevant to the answer, you may ignore it.\n",
        "\n",
        "    QUESTION: '{query}'\n",
        "                           \n",
        "    PASSAGE: '{relevant_passage}'\n",
        "\n",
        "    ANSWER:\n",
        "  \"\"\").format(query=query, relevant_passage=escaped)\n",
        "\n",
        "\n",
        "  return prompt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mlpDRG3cVvQE"
      },
      "outputs": [],
      "source": [
        "prompt = make_prompt(query, passage)\n",
        "Markdown(prompt)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qmdYdoIHcEc_"
      },
      "source": [
        "Choose one of the Gemini content generation models in order to find the answer to your query."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "m30avD9cfQQ-"
      },
      "outputs": [],
      "source": [
        "MODEL_ID = \"gemini-2.5-flash\" # @param [\"gemini-2.5-flash-lite\", \"gemini-2.5-flash\", \"gemini-2.5-pro\"] {\"allow-input\":true, isTemplate: true}\n",
        "answer = client.models.generate_content(\n",
        "    model=MODEL_ID,\n",
        "    contents=prompt,\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "COBhn6J9S_xI"
      },
      "outputs": [],
      "source": [
        "Markdown(answer.text)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-ocgBrOEXZbT"
      },
      "source": [
        "## Next steps\n",
        "\n",
        "Check out the [embeddings quickstart](https://github.com/google-gemini/cookbook/blob/main/quickstarts/Embeddings.ipynb) to learn more, and browse the cookbook for more [examples](https://github.com/google-gemini/cookbook/tree/main/examples)."
      ]
    }
  ],
  "metadata": {
    "colab": {
      "name": "Talk_to_documents_with_embeddings.ipynb",
      "toc_visible": true
    },
    "google": {
      "image_path": "/site-assets/images/share.png",
      "keywords": [
        "examples",
        "googleai",
        "samplecode",
        "python",
        "embed"
      ]
    },
    "kernelspec": {
      "display_name": "partij_programma_wijzer",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.6"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
